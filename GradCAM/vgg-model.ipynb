{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 38601,
     "sourceType": "datasetVersion",
     "datasetId": 30279
    }
   ],
   "dockerImageVersionId": 31040,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"jessicali9530/caltech256\")\n\nprint(\"Path to dataset files:\", path)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:24.331623Z",
     "iopub.execute_input": "2025-06-08T11:02:24.331871Z",
     "iopub.status.idle": "2025-06-08T11:02:24.459164Z",
     "shell.execute_reply.started": "2025-06-08T11:02:24.331844Z",
     "shell.execute_reply": "2025-06-08T11:02:24.458399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Path to dataset files: /kaggle/input/caltech256\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": "from pathlib import Path\n\nfrom torchvision.models import resnet18, efficientnet_b0\n\nroot_dir = path + '/256_ObjectCategories'\n\ndef get_folder_frequency_list(root_dir):\n    folder_frequency_list = []\n\n    root_path = Path(root_dir)\n\n    for folder in sorted(root_path.iterdir()):\n        if folder.is_dir():\n            file_count = sum(1 for item in folder.iterdir() if item.is_file())\n            folder_frequency_list.extend([folder.name.split('.')[0]] * file_count)\n\n    return folder_frequency_list\n\ntargets = get_folder_frequency_list(root_dir)\ntargets_int = [int(x) for i,x in enumerate(targets)]\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:24.523240Z",
     "iopub.execute_input": "2025-06-08T11:02:24.523894Z",
     "iopub.status.idle": "2025-06-08T11:02:51.591016Z",
     "shell.execute_reply.started": "2025-06-08T11:02:24.523871Z",
     "shell.execute_reply": "2025-06-08T11:02:51.590276Z"
    }
   },
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": "import torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\nroot_dir = '/kaggle/input/'\n\ntransform1 = transforms.Compose([\n    transforms.Resize((299, 299)),\n    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n    # transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n])\n\ntransform2 = transforms.Compose([\n    transforms.Resize((256, 256)),\n    # transforms.Lambda(lambda img: img.convert(\"RGB\")),\n    transforms.CenterCrop(224),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n])\n\ninception_dataset = datasets.Caltech256(root=root_dir, transform = transform1, target_transform = None,  download=False)\nresnet_dataset = datasets.Caltech256(root=root_dir, transform=transform2, target_transform=None, download= False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:51.599220Z",
     "iopub.execute_input": "2025-06-08T11:02:51.599437Z",
     "iopub.status.idle": "2025-06-08T11:02:51.911023Z",
     "shell.execute_reply.started": "2025-06-08T11:02:51.599416Z",
     "shell.execute_reply": "2025-06-08T11:02:51.910286Z"
    }
   },
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\n\nindices = np.arange(len(inception_dataset))\n\nif len(indices) != len(targets_int):\n    del targets_int[0]\n    targets_int = np.array(targets_int)\n\ntrain_indices, temp_indices, _, _ = train_test_split(indices, targets_int, test_size=0.3, stratify=targets_int, random_state=42)\n\nval_indices, test_indices, _, _ = train_test_split(temp_indices, [targets_int[i] for i in temp_indices], test_size=0.5, stratify=[targets_int[i] for i in temp_indices], random_state=42)\n\ntrain_dataset = torch.utils.data.Subset(inception_dataset, train_indices)\nval_dataset = torch.utils.data.Subset(inception_dataset, val_indices)\ntest_dataset = torch.utils.data.Subset(inception_dataset, test_indices)\n\n\nprint(f\"Train size: {len(train_dataset)}\")\nprint(f\"Validation size: {len(val_dataset)}\")\nprint(f\"Test size: {len(test_dataset)}\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:51.911937Z",
     "iopub.execute_input": "2025-06-08T11:02:51.912208Z",
     "iopub.status.idle": "2025-06-08T11:02:51.958467Z",
     "shell.execute_reply.started": "2025-06-08T11:02:51.912186Z",
     "shell.execute_reply": "2025-06-08T11:02:51.957640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Train size: 21424\nValidation size: 4591\nTest size: 4592\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\n\nindices = np.arange(len(resnet_dataset))\n\nif len(indices) != len(targets_int):\n    del targets_int[0]\n    targets_int = np.array(targets_int)\n\ntrain_indices, temp_indices, _, _ = train_test_split(indices, targets_int, test_size=0.3, stratify=targets_int, random_state=42)\n\nval_indices, test_indices, _, _ = train_test_split(temp_indices, [targets_int[i] for i in temp_indices], test_size=0.5, stratify=[targets_int[i] for i in temp_indices], random_state=42)\n\ntrain_dataset = torch.utils.data.Subset(resnet_dataset, train_indices)\nval_dataset = torch.utils.data.Subset(resnet_dataset, val_indices)\ntest_dataset = torch.utils.data.Subset(resnet_dataset, test_indices)\n\nprint(f\"Train size: {len(train_dataset)}\")\nprint(f\"Validation size: {len(val_dataset)}\")\nprint(f\"Test size: {len(test_dataset)}\")\n\nresnet_train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nresnet_val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)\nresnet_test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:51.959440Z",
     "iopub.execute_input": "2025-06-08T11:02:51.959860Z",
     "iopub.status.idle": "2025-06-08T11:02:51.991503Z",
     "shell.execute_reply.started": "2025-06-08T11:02:51.959814Z",
     "shell.execute_reply": "2025-06-08T11:02:51.990658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Train size: 21424\nValidation size: 4591\nTest size: 4592\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": "def topk_accuracy(model, loader, device, k=5):\n    \n    model.eval()\n    correct_topk = 0\n    total = 0\n\n    with torch.no_grad():\n\n        for images, labels in loader:\n            \n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, topk_preds = outputs.topk(k, dim=1) \n\n            correct_topk += sum([label in topk for topk, label in zip(topk_preds, labels)])\n            total += labels.size(0)\n\n    return correct_topk / total\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T07:06:29.193577Z",
     "iopub.execute_input": "2025-06-08T07:06:29.194042Z",
     "iopub.status.idle": "2025-06-08T07:06:29.198541Z",
     "shell.execute_reply.started": "2025-06-08T07:06:29.194025Z",
     "shell.execute_reply": "2025-06-08T07:06:29.197992Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\n\nclass ResNetModule(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n\n        super(ResNetModule, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n\n    def forward(self, x):\n      \n        identity = x\n\n        pred = self.relu(self.bn1(self.conv1(x)))\n        pred = self.relu(self.bn2(self.conv2(pred)))\n        pred = self.bn3(self.conv3(pred))\n\n        if self.downsample:\n            identity = self.downsample(x)\n\n        pred += identity\n        pred = self.relu(pred)\n\n        return pred\n\n\n\n\n\n\nclass myResNet50(nn.Module):\n\n    def __init__(self):\n        \n        super(myResNet50, self).__init__()\n\n        self.in_channels = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self.make_layer(ResNetModule, 64, 3)\n        self.layer2 = self.make_layer(ResNetModule, 128, 4, stride=2)\n        self.layer3 = self.make_layer(ResNetModule, 256, 6, stride=2)\n        self.layer4 = self.make_layer(ResNetModule, 512, 3, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * ResNetModule.expansion, 512)\n        \n    \n\n\n    def make_layer(self, block, out_channels, blocks, stride=1):  #Some help taken from ai here\n\n        downsample = None\n\n        if stride != 1 or self.in_channels != out_channels * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * block.expansion),\n            )\n\n        layers = [block(self.in_channels, out_channels, stride, downsample)]    \n        self.in_channels = out_channels * block.expansion\n\n        for _ in range(1, blocks):\n            layers.append(block(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:51.993436Z",
     "iopub.execute_input": "2025-06-08T11:02:51.994030Z",
     "iopub.status.idle": "2025-06-08T11:02:52.009988Z",
     "shell.execute_reply.started": "2025-06-08T11:02:51.994000Z",
     "shell.execute_reply": "2025-06-08T11:02:52.009034Z"
    }
   },
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": "import torch.nn.functional as F\n\nclass InceptionModule(nn.Module):\n\n    def __init__(self, in_channels, b1, b2a, b2b, b3a, b3b, pool_proj):\n\n        super(InceptionModule, self).__init__()\n\n        self.branch1 = nn.Conv2d(in_channels, b1, kernel_size=1)\n\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels, b2a, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv2d(b2a, b2b, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.Conv2d(in_channels, b3a, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv2d(b3a, b3b, kernel_size=5, padding=2),\n            nn.ReLU()\n        )\n\n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n\n        return torch.cat([\n            self.branch1(x),\n            self.branch2(x),\n            self.branch3(x),\n            self.branch4(x)\n        ], 1)\n\n\n\n\n\nclass myInceptionV3(nn.Module):\n\n    def __init__(self, num_classes=257):\n\n        super(myInceptionV3, self).__init__()\n        self.pre_layers = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=2),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2)\n        )\n\n        self.inception3a = InceptionModule(64, 64, 48, 64, 64, 96, 32)\n        self.inception3b = InceptionModule(256, 64, 48, 64, 64, 96, 64)\n\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n        self.inception4a = InceptionModule(288, 64, 48, 64, 64, 96, 64)\n        self.inception4b = InceptionModule(288, 64, 48, 64, 64, 96, 64)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.4)\n        self.fc = nn.Linear(288, num_classes)\n\n\n    def forward(self, x):\n\n        x = self.pre_layers(x)\n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool(x)\n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)   #This was suggested by ai\n        x = self.dropout(x)\n        x = self.fc(x)\n\n        return x",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:52.010819Z",
     "iopub.execute_input": "2025-06-08T11:02:52.011116Z",
     "iopub.status.idle": "2025-06-08T11:02:52.030023Z",
     "shell.execute_reply.started": "2025-06-08T11:02:52.011099Z",
     "shell.execute_reply": "2025-06-08T11:02:52.029178Z"
    }
   },
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": "import torchvision.models as models\nimport torch.optim as optim\n\nclass Ensembler:\n\n    def __init__(self, model1, model2):\n        \n        pre1 = models.resnet50(pretrained = True)\n        self.my1 = model1\n\n        my_w = self.my1.state_dict()\n        pre_w = pre1.state_dict()\n\n        matched = {}\n\n        for i, j in pre_w.items():\n            if i in my_w and j.shape == my_w[i].shape:\n                matched[i] = j\n\n        my_w.update(matched)\n        self.my1.load_state_dict(my_w)\n        \n        torch.save(self.my1.state_dict(), \"resnet50.pth\")\n        self.my1.load_state_dict(torch.load(\"resnet50.pth\"))\n\n        \n        pre2 = models.inception_v3(pretrained = True)\n        self.my2 = model2\n\n        my_w = self.my2.state_dict()\n        pre_w = pre2.state_dict()\n\n        matched = {}\n\n        for i, j in pre_w.items():\n            if i in my_w and j.shape == my_w[i].shape:\n                matched[i] = j\n\n        my_w.update(matched)\n        self.my2.load_state_dict(my_w)\n\n        torch.save(self.my2.state_dict(), \"inception_v3.pth\")\n        self.my2.load_state_dict(torch.load(\"inception_v3.pth\"))\n\n\n        self.criterion = nn.CrossEntropyLoss()\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    def optimizers(self, mode):\n        return optim.Adam(filter(lambda p: p.requires_grad, mode.parameters()), lr=1e-4)\n\n    def fine_tune(self, model, dataloader, criterion, epochs, device):\n\n        for params in model.parameters():\n            params.require_grad = False\n        for params in model.fc.parameters():\n            params.require_grad = True\n\n        optimizer = self.optimizers(model)\n        \n        for epoch in range(epochs):\n            model.train()\n            total_loss = 0\n            \n            for images, labels in dataloader:\n                images, labels = images.to(device), labels.to(device)\n\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n\n            total_loss += loss.item()\n\n            print(f\"Epoch:{epoch+1}, Loss:{total_loss}\")\n\n\n    def topk_performance(self, model, loader, device, k):\n    \n            model.eval()\n            correct_topk = 0\n            total = 0\n    \n            with torch.no_grad():\n    \n                for images, labels in loader:\n                \n                    images, labels = images.to(device), labels.to(device)\n                    outputs = model(images)\n                    _, topk_preds = outputs.topk(k, dim=1) \n    \n                    correct_topk += sum([label in topk for topk, label in zip(topk_preds, labels)])\n                    total += labels.size(0)\n    \n            return correct_topk / total\n            \n\n    def fine_tune_ensembler(self, train_resnet, train_inception):\n\n        print(\"Fine tuning resnet50.\")\n        self.fine_tune(self.my1, train_resnet, self.criterion, 20, self.device)\n\n        print(\"Fine tuning inception_v3.\")\n        self.fine_tune(self.my2, train_inception, self.criterion, 20, self.device)\n\n    \n    ",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:55.344789Z",
     "iopub.execute_input": "2025-06-08T11:02:55.345348Z",
     "iopub.status.idle": "2025-06-08T11:02:55.356753Z",
     "shell.execute_reply.started": "2025-06-08T11:02:55.345319Z",
     "shell.execute_reply": "2025-06-08T11:02:55.355869Z"
    }
   },
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": "device = 'cuda'\n\nmodel1 = myResNet50().to(device)\nmodel2 = myInceptionV3().to(device)\n\nensemble = Ensembler(model1, model2)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:02:59.084305Z",
     "iopub.execute_input": "2025-06-08T11:02:59.084573Z",
     "iopub.status.idle": "2025-06-08T11:03:00.455710Z",
     "shell.execute_reply.started": "2025-06-08T11:02:59.084555Z",
     "shell.execute_reply": "2025-06-08T11:03:00.455017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": "ensemble.fine_tune_ensembler(resnet_train_loader, train_loader)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T11:03:03.977450Z",
     "iopub.execute_input": "2025-06-08T11:03:03.977746Z",
     "iopub.status.idle": "2025-06-08T12:18:42.788771Z",
     "shell.execute_reply.started": "2025-06-08T11:03:03.977722Z",
     "shell.execute_reply": "2025-06-08T12:18:42.787906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Fine tuning resnet50.\nEpoch:1, Loss:1.647470474243164\nEpoch:2, Loss:1.31736421585083\nEpoch:3, Loss:0.24041448533535004\nEpoch:4, Loss:0.1425720602273941\nEpoch:5, Loss:0.06755145639181137\nEpoch:6, Loss:0.028846291825175285\nEpoch:7, Loss:0.011470510624349117\nEpoch:8, Loss:0.005069027189165354\nEpoch:9, Loss:0.011143187992274761\nEpoch:10, Loss:0.004602707922458649\nEpoch:11, Loss:0.005529246758669615\nEpoch:12, Loss:0.006758340168744326\nEpoch:13, Loss:0.030282966792583466\nEpoch:14, Loss:0.35267373919487\nEpoch:15, Loss:0.14541758596897125\nEpoch:16, Loss:0.01237315684556961\nEpoch:17, Loss:0.008470219559967518\nEpoch:18, Loss:0.0029532008338719606\nEpoch:19, Loss:0.0016067521646618843\nEpoch:20, Loss:0.003948498982936144\nFine tuning inception_v3.\nEpoch:1, Loss:5.377089500427246\nEpoch:2, Loss:5.356916427612305\nEpoch:3, Loss:4.549125671386719\nEpoch:4, Loss:5.200327396392822\nEpoch:5, Loss:4.8500847816467285\nEpoch:6, Loss:4.796204566955566\nEpoch:7, Loss:4.51137638092041\nEpoch:8, Loss:4.774440288543701\nEpoch:9, Loss:5.114279270172119\nEpoch:10, Loss:4.494928359985352\nEpoch:11, Loss:3.4599945545196533\nEpoch:12, Loss:3.9861063957214355\nEpoch:13, Loss:3.6189451217651367\nEpoch:14, Loss:5.123126029968262\nEpoch:15, Loss:4.014986991882324\nEpoch:16, Loss:3.8735835552215576\nEpoch:17, Loss:4.397487163543701\nEpoch:18, Loss:4.137771129608154\nEpoch:19, Loss:3.2681219577789307\nEpoch:20, Loss:3.1186838150024414\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": "ensemble.topk_performance(ensemble.my1, resnet_train_loader, device, 5)\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T12:30:24.019529Z",
     "iopub.execute_input": "2025-06-08T12:30:24.020242Z",
     "iopub.status.idle": "2025-06-08T12:32:39.755076Z",
     "shell.execute_reply.started": "2025-06-08T12:30:24.020218Z",
     "shell.execute_reply": "2025-06-08T12:32:39.754299Z"
    }
   },
   "outputs": [
    {
     "execution_count": 60,
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {}
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": "ensemble.topk_performance(ensemble.my2, train_loader, device, 5)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-06-08T12:32:39.756280Z",
     "iopub.execute_input": "2025-06-08T12:32:39.756914Z",
     "iopub.status.idle": "2025-06-08T12:35:08.088364Z",
     "shell.execute_reply.started": "2025-06-08T12:32:39.756893Z",
     "shell.execute_reply": "2025-06-08T12:35:08.087557Z"
    }
   },
   "outputs": [
    {
     "execution_count": 61,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.42564413741598206"
     },
     "metadata": {}
    }
   ],
   "execution_count": 61
  }
 ]
}
